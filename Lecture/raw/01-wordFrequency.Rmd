---
output:
  word_document: 
    fig_height: 6
    fig_width: 8
    reference_docx: "../template/WordTemplate_EasyR_Text.docx"
    toc: true
    toc_depth: 2
toc-title: "목차"
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::knit_child("../rmd_etc/rmd_options.Rmd")
```


# 1 어떤 이야기를 가장 많이 했을까? - 단어 빈도 분석

문장은 단어가 연결되어 만들어집니다. 텍스트에 자주 사용된 단어가 무엇인지 분석하면 글쓴이가 무엇을 강조했는지, 글의 핵심 주제와 의도는 무엇인지 쉽게 파악할 수 있습니다. 이 장에서는 텍스트에 자주 사용된 단어를 알아보는 단어 빈도(Word Frequency) 분석 방법을 익혀 보겠습니다.

> [편집] 설명 그림 삽입


## 1.1 대통령 연설문으로 시작하는 텍스트 전처리

텍스트 전처리란 본격적으로 분석 작업을 시작하기 전에 분석할 텍스트의 불필요한 요소들을 제거하고 데이터를 다루기 쉬운 형태로 만드는 과정을 의미합니다. 문재인 대통령 출마 연설문을 이용해 텍스트 전처리 작업부터 단어 빈도 분석하는 방법까지 한 단계씩 알아보겠습니다. 

대통령 연설문은 이해하기 쉬운 단어와 문법 오류가 없는 정제된 문장으로 구성되어 있습니다. 전처리 작업을 많이 하지 않아도 되기 때문에 초보자가 텍스트 분석 방법을 익히는데 매우 적합한 자료입니다.

### 1.1.1 연설문 불러오기

`text_moon.txt`에는 문재인 대통령 대선 출마 선언문이 담겨 있습니다. `text_moon.txt`를 `readLines()`를 이용해 불러오겠습니다.

```{r, eval=F}
raw_moon <- readLines("speech_moon.txt", encoding = "UTF-8")
head(raw_moon)
```

> [참고] `speech_moon.txt`는 `UTF-8` 인코딩으로 되어있습니다.


```{r, echo=F}
raw_moon <- readLines(here::here("files/speech_moon.txt"), encoding = "UTF-8")
head(raw_moon)
```

> [편집] 빈줄 삭제

<br>

> [참고] 실습 파일을 다운로드하는 방법은 00쪽을 참고하세요.

> 문재인 대통령 대선 출마 선언문 출처 [ko.wikisource.org/wiki/문재인_출마선언문](https://ko.wikisource.org/wiki/문재인_출마선언문)


### 1.1.2 불필요한 문자 제거하기 - `str_replace_all()`

 `raw_moon`을 출력한 결과를 보면 특수문자, 한자, 공백 등이 포함되어 있습니다. 이런 요소는 분석 대상이 아니므로 제외해야 합니다.
 
 `stringr` 패키지의 `str_replace_all()`은 텍스트에서 특정 규칙에 해당하는 문자를 찾아 다른 문자로 바꾸는 기능을 합니다. `str_replace_all()`을 이용하면 불필요한 문자를 제거할 수 있습니다.
 

#### 샘플 텍스트로 동작 원리 알아보기

우선 샘플 텍스트를 이용해 `str_replace_all()`이 어떻게 동작하는지 살펴보겠습니다. `str_replace_all()`에는 다음 세 가지 파라미터를 입력해야 합니다.

- `string` : 처리할 텍스트

- `pattern` : 규칙

- `replacement` : 바꿀 문자

다음 코드에서 `pattern`에 입력한 `[^가-힣]`은 '한글이 아닌 모든 문자'를 의미하는 **정규 표현식(Regular expression)**입니다. `replacement`에는 공백 `" "`을 입력했습니다. 따라서 출력 결과를 보면 한글을 제외한 모든 문자가 공백으로 바뀌게 됩니다.

```{r}
txt <- "치킨은!! 맛있다. xyz 정말 맛있다!@#"
txt
```

```{r eval=F}
install.packages("stringr")
library(stringr)

str_replace_all(string = txt, pattern = "[^가-힣]", replacement = " ")
```

```{r echo=F}
# install.packages("stringr")
library(stringr)

str_replace_all(string = txt, pattern = "[^가-힣]", replacement = " ")
```

> [알아두면 좋아요] 정규 표현식이란?

> '정규 표현식'은 특정한 규칙을 가진 문자열을 표현하는 언어입니다. 특정 조건의 문자를 찾거나 수정할 때 정규 표현식을 활용합니다. 앞 코드에 사용한 정규 표현식 `[^가-힣]`에서 `가-힣`은 `"가"` 부터 `"힣"`까지의 모든 한글 문자를 의미하고 `^`는 '반대'를 의미합니다. 따라서 `[^가-힣]`은 '한글이 아닌 모든 문자'를 의미합니다. 정규 표현식을 자세히 알고 싶다면 아래 영상을 참고하세요.

> [opentutorials.org/module/622/5143](opentutorials.org/module/622/5143)


#### `raw_moon`의 불필요한 문자 제거하기

`str_replace_all()` 사용법을 익혔으니 `raw_moon`에 적용해 불필요한 문자를 제거하겠습니다.

```{r}
moon <- raw_moon %>%
 str_replace_all("[^가-힣]", " ")

head(moon)
```

> [편집] 빈줄 삭제

---

> [알아두면 좋아요] 파라미터명 생략하기

> 함수의 파라미터는 순서가 정해져 있기 때문에 순서를 알고 있으면 파라미터명을 일일이 입력하지 않아도 됩니다. 파라미터의 순서는 함수 설명 문서의 Arguments 항목을 보면 알 수 있습니다. `?str_replace_all`과 같이 함수명 앞에 물음표를 붙여 실행하면 R 스튜디오 우측 하단 Help 창에 설명 문서가 나타납니다. 

```{r, eval = F}
# 파라미터명 입력
str_replace_all(string = txt, pattern = "[^가-힣]", replacement = " ")

# 파라미터명 생략
str_replace_all(txt, "[^가-힣]", " ")
```

---

### 1.1.3 연속된 공백 제거하기 - `str_squish()`

앞에서 출력한 결과를 보면 한글을 제외한 모든 문자를 공백으로 바꾸었기 때문에 연속된 공백이 포함되어 있습니다. `stringr` 패키지의 `str_squish()`를 이용하면 연속된 공백을 제거하고 공백을 하나만 남길 수 있습니다.

#### 샘플 텍스트로 동작 원리 알아보기

샘플 텍스트에 `str_squish()`를 적용해 보겠습니다. 다음 코드를 실행하면 연속된 공백이 제거되고 공백이 하나만 남았을을 확인할 수 있습니다.

```{r}
txt <- "치킨은  맛있다   정말 맛있다  "
txt
str_squish(txt)
```


#### `moon`에 있는 연속된 공백 제거하기

연설문에 `str_squish()`을 적용하겠습니다. 다음 코드의 출력 결과를 보면 공백이 하나만 남았음을 알 수 있습니다.

```{r}
moon <- moon %>%
 str_squish()

head(moon)
```


### 1.1.4 텍스트 데이터를 tibble 구조로 바꾸기

`moon`은 문자가 나열된 문자열 벡터(Character Vectors) 구조로 되어 있습니다. 문자열 벡터는 행에 들어있는 모든 내용을 출력하기 때문에 긴 문자가 들어있으면 출력 결과를 알아보기 어렵습니다. 

#### 문자열 벡터를 tibble 구조로 바꾸기 - `as_tibble()`

`dplyr` 패키지의 `as_tibble()`을 이용해 문자열 벡터를 tibble 구조로 변환하면 텍스트가 보기 편하게 출력 됩니다. 또한, 앞으로 익힐 텍스트 처리 함수를 쉽게 적용할 수 있는 상태가 됩니다.

```{r}
library(dplyr)
moon <- as_tibble(moon)
moon
```

tibble 구조로 변환한 `moon`을 출력하면 한 행에 한 단락이 들어있고, 긴 문장은 Console 창에서 보기 편할 만큼 일부만 출력됩니다. `A tibble: 117 x 1`을 보면 `moon`이 117개의 행과 1개의 열로 구성되어 있음을 알 수 있습니O다. 그 아래를 보면 `moon`에 들어있는 변수명은 `value`이며 자료형은 `<chr>` 문자임을 알 수 있습니다.


> [참고] 실행 결과를 보면 문자가 없는 빈 행이 포함되어 있습니다. 이것은 원자료의 문장에 줄바꿈이 사용되었기 때문입니다. 빈 행은 이후 단어를 추출하는 과정에서 제거하겠습니다.

#### 전처리 작업 한 번에 하기

`%>%`를 이용해 함수를 연결하면 텍스트에서 한글만 남기고, 연속된 공백을 제거한 다음, tibble 구조로 변환하는 작업을 한 번에 할 수 있습니다.
```{r eval=F}
moon <- raw_moon %>%
 str_replace_all("[^가-힣]", " ") %>%  # 한글만 남기기
 str_squish() %>%                      # 연속된 공백 제거
 as_tibble()                           # tibble로 변환
```


> [알아두면 좋아요] tibble과 data frame

tibble은 data frame을 다루기 편하게 개선한 자료 구조입니다. data frame은 콘솔 창에 모든 데이터를 출력하는 반면 tibble은 콘솔 창 크기에 맞게 일부만 출력하기 때문에 구조를 파악하기 편합니다. 또한 tibble은 데이터의 행, 열의 개수와 변수의 속성도 알려줍니다. `iris`는 R에 내장된 data frame 구조의 데이터셋입니다. RStudio 콘솔 창 크기를 작게 조정한 다음 `iris`를 tibble로 변환해 출력하면 data frame과 어떤 차이가 있는지 알 수 있습니다.

```{r eval=F}
iris  # data frame 출력
```

```{r echo=F}
iris %>% head(10)
```

> [편집] 결과 생략 표시

```{r echo=F}
options(tibble.width = 55)      # tibble 출력 폭 제한
```

```{r}
as_tibble(iris)  # tibble 구조로 변환
```

```{r echo=F}
options(tibble.width = NULL)      # tibble 출력 폭 제한 되돌리기
```

---

> [편집] 풍선 설명 

> A tibble: 150 x 5 - 행, 열의 개수
> <dbl>       <dbl>        <dbl>       <dbl> <fct> - 변수의 속성
> ... with 140 more rows, and 1 more variable:
> Species <fct>  - 출력되지 않은 행, 열의 정보

---


## 1.2 토큰화하기

텍스트는 단락, 문장, 단어, 형태소 등 다양한 단위로 나눌 수 있습니다. 이런 텍스트의 기본 단위를 **토큰(Token)**이라고 합니다. 기본적인 전처리 작업이 끝나면 텍스트를 분석 목적에 따라 토큰으로 나누는 작업을 하게 되는데, 이를 **토큰화(Tokenization)**라고 합니다.


#### 토큰화하기 - `unnest_tokens()`

`tidytext`는 텍스트를 **정돈된 데이터(Tidy Data)** 형태를 유지하며 분석할 수 있게 도와주는 패키지입니다. `tidytext` 패키지를 이용하면 `dplyr`, `ggplot2`와 같이 데이터를 다룰 때 자주 사용하는 패키지들을 함께 활용하며 편리하게 텍스트를 분석할 수 있습니다.

`tidytext` 패키지의 `unnest_tokens()`를 이용하면 텍스트를 토큰화할 수 있습니다. 우선 샘플 텍스트를 토큰화해 동작 원리를 알아 본 다음 연설문을 토큰화하겠습니다.

#### 샘플 텍스트로 동작 원리 알아보기

먼저 `dplyr` 패키지의 `tibble()`을 이용해 tibble 구조의 데이터를 만들겠습니다. 다음 코드를 실행하면 샘플 텍스트를 변수 `value`에 담아 tibble 구조로 만들어 출력합니다.

```{r}
text <- tibble(value = "대한민국은 민주공화국이다. 대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.")
text
```

`unnest_tokens()`를 이용해 텍스트를 토큰화하겠습니다. `unnest_tokens()`에는 세 가지 파라미터를 입력해야 합니다.

- `input` : 분석 대상이 되는 변수명
- `output` : 함수 실행 결과로 만들 변수명
- `token` : 텍스트를 나눌 기준 값. 문장 기준으로 나누려면 `"sentences"`, 띄어쓰기 기준으로 나누려면 `"words"`, 글자 기준으로 나누려면 `"characters"`를 입력하면 됩니다.

샘플 텍스트에 적용한 결과를 보면 텍스트가 `token`에 입력한 기준으로 나뉘어 각 행으로 구성됐음을 확인할 수 있습니다.

```{r eval=F}
install.packages("tidytext")
library(tidytext)

# 문장 기준 토큰화
text %>%
  unnest_tokens(input = value,        # 분석 대상
                output = word,        # 출력 변수명
                token = "sentences")  # 토큰 기준
```

```{r echo=F}
# install.packages("tidytext")
library(tidytext)

# 문장 기준 토큰화
text %>%
  unnest_tokens(input = value,        # 토큰화할 텍스트
                output = word,        # 출력 변수명
                token = "sentences")  # 토큰화 기준
```

```{r}
# 띄어쓰기 기준 토큰화
text %>%
  unnest_tokens(input = value,
                output = word,
                token = "words")      # 띄어쓰기 기준
```

```{r}
# 문자 기준 토큰화
text %>%
  unnest_tokens(input = value,
                output = word,
                token = "characters")  # 문자 기준
```

> [참고] `unnest_tokens()`에는 tibble이나 데이터 프레임 구조의 변수를 입력해야 하니 주의하세요. 데이터를 tibble 구조로 변환하려면 `as_tibble()`을 이용하면 됩니다.

#### `moon` 토큰화하기

`unnest_tokens()` 사용법을 익혔으니 이제 연설문에 적용해 보겠습니다. 어떤 단어가 많이 사용 되었는지 알아보는 것이 목적이므로 연설문을 띄어쓰기 기준으로 토큰화하겠습니다.
```{r}
word_space <- moon %>%
  unnest_tokens(input = value,
                output = word,
                token = "words")
word_space
```


## 1.3 단어 빈도 분석하기

텍스트에 단어가 몇 번 사용됐는지 알아보는 분석 방법을 **단어 빈도 분석**이라고 합니다. 자주 사용된 단어를 보면 글쓴이가 무엇을 강조했는지 알 수 있기 때문에 텍스트를 분석할 때 가장 먼저 단어 빈도를 구하게 됩니다. 연설문을 이용해 단어 빈도 분석을 하는 방법을 알아보겠습니다.

### 1.3.1 단어 빈도 구하기 - `count()`

연설문을 띄어쓰기 기준으로 나눴으니 이제 빈도를 구해 어떤 단어가 많이 사용되었는지 알아보겠습니다. `dplyr` 패키지의 `count()`를 이용하면 단어의 빈도를 구할 수 있습니다. `count()`에 `sort = T`를 입력하면 빈도가 높은 순으로 단어를 정렬합니다.

```{r}
word_space <- word_space %>%
 count(word, sort = T)

word_space
```

출력 결과를 보면 연설문에 어떤 단어가 얼마나 많이 사용되었는지 알 수 있습니다. "합니다"가 27번으로 가장 많이 사용됐고, 그 뒤로는 "수", "있습니다"가 많이 사용됐습니다. 또한 `A tibble: 1,440 x 2`를 보면 연설문이 총 1,440개의 단어로 구성된다는 점도 알 수 있습니다.

> [참고] 대부분의 단어가 '합니다', '있습니다'와 같은 서술어로 구성되어 있는 이유는 텍스트를 토큰화한 기준이 띄어쓰기이기 때문입니다. 텍스트의 의미를 파악하려면 의미를 결정하는 단위로 텍스트를 토큰화해야 합니다. 이 방법은 뒤에서 자세히 다룹니다.


### 1.3.2 한 글자로 된 단어 제거하기

`word_space` 출력 결과를 보면 "수", "등" 처럼 한 글자로 된 단어가 많이 포함되어 있습니다. 한 글자로 된 단어는 문장에서 어떤 의미로 사용되었는지 알기 어렵기 때문에 분석에서 제외하는 게 좋습니다.

#### 한 글자로 된 단어 제거하기 - `fitler(str_count())`

`stringr` 패키지의 `str_count()`는 문자열의 글자 수를 구하는 기능을 합니다.

```{r}
str_count("배")
str_count("사과")
```

`str_count()`로 단어의 글자 수를 구한 다음, `filter()`를 이용해 `1`보다 큰 행을 추출하면 한 글자로 된 단어를 제거할 수 있습니다. 다음 코드를 실행하면 한 글자로 된 단어가 제거되어 1,384개 단어가 남았음을 확인할 수 있습니다.

```{r}
# 두 글자 이상만 남기기
word_space <- word_space %>%
 filter(str_count(word) > 1)

word_space
```


#### 한 번에 작업하기

`%>%`를 이용해 `count()` 함수와 `filter()` 함수를 연결하면 단어의 빈도를 구한 다음, 내림차순으로 정렬하고, 두 글자 이상 단어만 남기는 코드를 다음과 같이 간략하게 작성할 수 있습니다.

```{r, eval = F}
word_space <- word_space %>%
 count(word, sort = T) %>%
 filter(str_count(word) > 1)
```


### 1.3.3 자주 사용된 단어 추출하기

단어 빈도 분석의 목적은 텍스트에서 가장 많이 사용된 단어를 알아내 텍스트의 핵심 주제를 파악하는 것입니다.

#### head()를 이용해 빈도가 높은 단어 추출하기

1,384개 단어로 구성된 `word_space`에서 빈도가 높은 상위 20개 단어를 추출하겠습니다. `word_space`는 빈도가 높은 순으로 정렬되어 있으므로 `head()`를 이용해 상위 20개 단어를 추출하면 됩니다.

```{r}
top20 <- word_space %>%
 head(20)

```


```{r eval=F}
top20
```

```{r, echo=F}
top20 %>% print(n = 10)
```


### 1.3.4 막대 그래프 만들기

이번에는 어떤 단어가 얼마나 많이 사용되었는지 쉽게 알아볼 수 있는 막대 그래프를 만들겠습니다.

#### 막대 그래프 만들기 - `geom_col()`

`ggplot2` 패키지의 `geom_col()`을 이용하면 막대 그래프를 만들 수 있습니다. 앞에서 생성한 `top20`을 이용해 막대 그래프를 만들겠습니다. 출력한 그래프를 보면 연설문에 어떤 단어가 얼마나 자주 사용됐는지 쉽게 파악할 수 있습니다.

```{r eval=F}
install.packages("ggplot2")
library(ggplot2)

ggplot(top20, aes(x = reorder(word, n), y = n)) +  # 단어 빈도순 정렬
 geom_col() +
 coord_flip()                                      # 회전
```

```{r echo=F}
# install.packages("ggplot2")
library(ggplot2)

ggplot(top20, aes(x = reorder(word, n), y = n)) +  # 단어 빈도순 정렬
 geom_col() +
 coord_flip()                                      # 회전
```

---

> [알아두면 좋아요] macOS에서 그래프에 한글 표현하기

macOS에서 그래프에 한글을 표현하려면 다음 코드를 실행해 `ggplot2` 패키지의 기본 테마 폰트를 한글 지원 폰트로 변경하면 됩니다.

```{r eval=F}
theme_set(theme_gray(base_family = "AppleGothic"))
```

> `ggplot()`에 `theme_minimal()` 등 테마를 바꾸는 함수를 사용하면 변경한 폰트가 적용되지 않습니다. 그럴 때는 `theme()`을 이용해 폰트를 직접 지정하면 됩니다. **1.3.6**을 참고하세요.

---


#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

- `geom_text()` : 텍스트 표시. 막대에 단어 빈도를 표시하겠습니다. `hjust`는 빈도를 막대 밖으로 이동하는 기능을 합니다.

- `labs()` : 제목 설정. 그래프 제목을 추가하겠습니다. 축 이름은 `NULL`을 입력해 삭제하겠습니다.

- `theme()`: 그래프 디자인 설정. 그래프 제목을 단어보다 크게 설정하겠습니다.

```{r}
ggplot(top20, aes(x = reorder(word, n), y = n)) +
 geom_col() +
 coord_flip() +
 geom_text(aes(label = n), hjust = -0.3) +            # 막대 밖 빈도 표시
  
 labs(title = "문재인 대통령 출마 선언문 단어 빈도",  # 그래프 제목
      x = NULL, y = NULL) +                           # 축 이름 삭제
  
 theme(title = element_text(size = 12))               # 제목 크기
```


### 1.3.5 워드 클라우드 만들기

워드 클라우드(Word cloud)는 단어 빈도를 구름 모양으로 표현한 그래프입니다. 워드 클라우드를 만들면 빈도에 따라 글자 크기와 색이 다르게 표현되므로 어떤 단어가 얼마나 많이 사용됐는지 한눈에 파악하기 좋습니다.

#### 워드 클라우드 만들기 - `geom_text_wordcloud()`

`ggwordcloud` 패키지의 `geom_text_wordcloud()`를 이용하면 워드 클라우드를 만들 수 있습니다. 연설문의 단어 빈도를 담고 있는 `word_space`를 이용해 워드 클라우드를 만들겠습니다. `geom_text_wordcloud()`는 난수를 이용하기 때문에 그래프를 만들 때마다 모양이 바뀝니다. `seed = 1234`를 입력하면 난수를 고정해 항상 같은 결과물을 만듭니다.

`scale_radius()`는 그래프에 표현할 텍스트의 범위를 설정하는 `ggplot2` 패키지 함수입니다. `scale_radius()`를 이용해 빈도가 3 이상인 단어만 표현하고, 글자 크기 범위를 3~30으로 설정하겠습니다. 이렇게 하면 빈도가 높은 단어를 강조할 수 있습니다.

```{r eval=F}
install.packages("ggwordcloud")
library(ggwordcloud)

ggplot(word_space, aes(label = word, size = n)) +
 geom_text_wordcloud(seed = 1234) +    
 scale_radius(limits = c(3, NA),     # 최소, 최대 단어 빈도
              range = c(3, 30))      # 최소, 최대 글자 크기
```


```{r echo=F}
# install.packages("ggwordcloud")
library(ggwordcloud)

ggplot(word_space, aes(label = word, size = n)) +
 geom_text_wordcloud(seed = 1234) +     
 scale_radius(limits = c(3, NA),     # 최소, 최대 단어 빈도
              range = c(3, 30))      # 최소, 최대 글자 크기
```

> [참고] RStudio 플롯 창 크기에 따라 그래프 모양이 달라집니다. 플롯 창을 크게 조정한 다음 다시 그래프를 만들어보세요.


#### 그래프 다듬기

`ggplot2` 패키지 함수를 이용해 그래프를 보기 좋게 수정하겠습니다.

- `scale_color_gradient()` : 빈도가 클수록 단어를 점점 진한 색으로 표현합니다. `low`에는 빈도가 최소일 때, `high`에는 빈도가 최대일 때 표현할 색을 지정합니다. `#`으로 시작하는 문자는 색상 코드(Hex Color Code) 입니다.

- `theme_minimal()` : 그래프에 배경이 없는 테마를 적용합니다. 이 외에도 `theme_bw()`, `theme_dark()` 등 다양한 테마를 적용할 수 있습니다.

```{r}
ggplot(word_space, 
       aes(label = word, 
           size = n, 
           col = n)) +                     # 빈도에 따라 색깔 표현
 geom_text_wordcloud(seed = 1234) +  
 scale_radius(limits = c(3, NA),
              range = c(3, 30)) +
 scale_color_gradient(low = "#66aaf2",     # 최소 빈도 색깔
                      high = "#004EA1") +  # 최고 빈도 색깔
 theme_minimal()                           # 배경 없는 테마 적용
```



> [참고] `ggwordcloud` 패키지를 이용해 워드 클라우드의 디자인을 다양하게 바꿀 수 있습니다. `ggwordcloud` 패키지 소개 [lepennec.github.io/ggwordcloud](https://lepennec.github.io/ggwordcloud/)

<br>

> [알아두면 좋아요] 워드 클라우드는 좋은 그래프인가?

> 워드 클라우드는 디자인이 아름다워서 텍스트를 표현할 때 자주 사용되지만 단어 빈도 분석 결과를 정확하게 표현하는 데는 적합하지 않습니다. 단어 빈도를 크기와 색으로 표현하므로 '어떤 단어가 정확히 몇 번 사용되었는지' 알 수 없고, 단어 배치가 어지러워 '어떤 단어가 다른 단어에 비해 얼마나 많이 사용되었는지' 비교하기 어렵기 때문입니다. 텍스트를 아름답게 표현하는게 아니라 분석 결과를 정확하게 표현하는 게 목적이라면 막대 그래프를 이용하길 권합니다.


### 1.3.6 그래프 폰트 설정하기

그래프의 폰트를 설정하면 한글을 아름답게 표현할 수 있습니다. 그래프의 폰트를 설정하는 방법을 알아보겠습니다.

#### 1. 구글 폰트 불러오기 - `font_add_google()`

`showtext` 패키지의 `font_add_google()`을 이용해 구글 폰트에서 사용할 폰트를 불러옵니다. 그런 다음 `showtext_auto()`를 실행해 폰트를 RStudio에 활용하도록 설정합니다. 다음 코드를 실행하면 구글 폰트에서 나눔고딕 폰트를 불러와 `"nanumgothic"`이라는 이름으로 저장하고, RStudio에서 활용하도록 설정합니다.

```{r eval=F}
install.packages("showtext")
library(showtext)

font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
```

```{r echo=F}
# install.packages("showtext")
library(showtext)
font_add_google(name = "Nanum Gothic", family = "nanumgothic")
showtext_auto()
```

> [참고] [fonts.google.com](fonts.google.com)에서 불러올 수 있는 폰트를 확인할 수 있습니다.

#### 2. 그래프에 폰트 적용하기

**1.3.5**에서 만든 워드 클라우드에 나눔고딕 폰트를 적용하겠습니다. `geom_text_wordcloud()`의 `family`에 폰트 이름 `nanumgothic`을 지정하면 됩니다.

```{r}
ggplot(word_space,
       aes(label = word,
           size = n,
           col = n)) +
  geom_text_wordcloud(seed = 1234,
                      family = "nanumgothic") +  # 폰트 적용
  scale_radius(limits = c(3, NA),
               range = c(3, 30)) +
  scale_color_gradient(low = "#66aaf2",
                       high = "#004EA1") +
  theme_minimal()
```

이번에는 워드 클라우드에 검은고딕 폰트를 적용해 보겠습니다.

```{r}
font_add_google(name = "Black Han Sans", family = "blackhansans")
showtext_auto()

ggplot(word_space,
       aes(label = word,
           size = n,
           col = n)) +
  geom_text_wordcloud(seed = 1234,
                      family = "blackhansans") +  # 폰트 적용
  scale_radius(limits = c(3, NA),
               range = c(3, 30)) +
  scale_color_gradient(low = "#66aaf2",
                       high = "#004EA1") +
  theme_minimal()
```

#### 3. `ggplot2` 패키지로 만든 그래프에 폰트 적용하기

`ggplot2` 패키지로 만든 그래프는 `theme()`을 이용해 폰트를 지정할 수 있습니다. **1.3.4**에서 만든 막대 그래프에 검은고딕 폰트를 적용해 보겠습니다.

```{r}
ggplot(top20, aes(x = reorder(word, n), y = n)) +
  geom_col() +
  coord_flip() +
  geom_text(aes(label = n), hjust = -0.3) +
  
  labs(title = "문재인 대통령 출마 연설문 단어 빈도",
       x = NULL, y = NULL) +
  
  theme(title = element_text(size = 12),
        text = element_text(family = "blackhansans"))  # 폰트 적용
```



> [알아두면 좋아요] RStudio를 실행할 때마다 `showtext` 패키지로 폰트를 설정해야 합니다.

> RStudio를 종료하면 폰트 설정이 사라집니다. RStudio를 새로 시작할 때마다 구글 폰트를 불러와 설정하는 코드를 한 번씩 실행해야 합니다. 2장부터는 그래프를 만들 때 나눔고딕 폰트를 사용합니다. 그래프를 만들기 전에 항상 폰트를 먼저 설정해주세요.

<br> 

> [알아두면 좋아요] `ggplot2` 기본 테마 폰트 변경하기

그래프를 만들 때 매번 `theme()`을 이용해 폰트를 지정하는게 번거롭다면 다음 코드를 실행해 `ggplot2` 패키지의 기본 테마 폰트를 설정하면 됩니다.

```{r eval=F}
theme_set(theme_gray(base_family = "nanumgothic"))
```

`ggplot2` 기본 테마 폰트를 설정하더라도 `theme_minimal()`, `theme_bw()`와 같이 테마를 바꾸는 함수를 사용하면 폰트가 기본값으로 되돌아갑니다. 그럴 때는 `theme()`을 이용해 폰트를 직접 지정해야 합니다.

---






